\section{逻辑亦数据}
% 从程序执行的视角开始，引入数据是如何编码逻辑的
\subsection{逻辑门}

这一章将视角从拟合上短暂地移开，我相信理解逻辑和数据的关系多少也会帮助我们理解神经网络。读者或许好奇过，计算是如何完成的呢？在讨论这个问题之前，先来做一个约定，我们将 0 视作\textoverset{False}{假}，1 视作\textoverset{True}{真}\footnote{逻辑0/1：在物理上，逻辑 0 由\textoverset{Low}{低电平}表示，逻辑 1 由\textoverset{High}{高电平}表示，TTL 和 CMOS 电路各有多种电压标准，感兴趣的读者可以自行学习电路的知识。}。先来看看几种最简单的逻辑运算。

\begin{enumerate}
    \item \textoverset{Not}{非}（数学写法：$\neg$，C 语言写法：\texttt{!}，Python 写法：\texttt{not}）
    
    非是一元运算符，它只有一个输入，输出与输入相反，其中
    \[
        \neg 0 = 1, \neg 1 = 0
    \]
    也就是说 $\neg x = 1 - x$，$x$ 与 $\neg x$ 是互补的。如果你看逻辑 0, 1 仍然感觉不太自然，你可以把它想成 False = not True, True = not False。

    \item \textoverset{And}{与}（数学写法：$\land$，C 语言写法：\texttt{\&\&}，Python 写法：\texttt{and}）
    
    与是二元运算符，它有两个输入，仅当两输入都为 1 时输出为 1，否则输出为 0，从真值表\footnote{真值表：逻辑运算的输出与输入的关系表。}就可以看出这一点：
    \[
        \begin{array}{ccc}
            \hline
            x & y & x \land y \\
            \hline
            0 & 0 & 0 \\
            0 & 1 & 0 \\
            1 & 0 & 0 \\
            1 & 1 & 1 \\
            \hline
        \end{array}
    \]
    这与乘法的结果是一样的，所以有时也会省去和的符号，使用 $xy$ 表示 $x \land y$。
    
    \item \textoverset{Or}{或}（数学写法：$\lor$，C 语言写法：\texttt{||}，Python 写法：\texttt{or}）
    
    或是二元运算符，它有两个输入，仅当两输入都为 0 时输出为 0，否则输出为 1，真值表如下：
    \[
        \begin{array}{ccc}
            \hline
            x & y & x \lor y \\
            \hline
            0 & 0 & 0 \\
            0 & 1 & 1 \\
            1 & 0 & 1 \\
            1 & 1 & 1 \\
            \hline
        \end{array}
    \]
\end{enumerate}

在图上这些运算一般会这样表示：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.2\textwidth]{img/not_gate.png}\quad
    \includegraphics[width=0.2\textwidth]{img/and_gate.png}\quad
    \includegraphics[width=0.2\textwidth]{img/or_gate.png}
    \caption{逻辑门：从左到右分别为非门、与门、或门}
\end{figure}

看起来这只是一些非常简单的运算，但是基本上有这些就可以构建出所有的计算\footnote{所有的运算：这里指的是\textoverset{Turing Completeness}{图灵完备性}，如果你想深入了解，可以在 Steam 上购买一个叫做 \uhref{https://store.steampowered.com/app/1444480/Turing_Complete/}{Turing Complete} 的硬核游戏，推荐游玩。}。例如\textoverset{Exclusive Or}{异或}运算表示两个输入中有且仅有一个为真。最粗暴简单的方法是列出它为 1 的所有情况：$x \; \text{xor} \; y = (x\land \neg y) \lor (\neg x \land y)$。这样我们就可以用非、与、或门来构建出一个异或门。

虽然它可以完成“所有的运算”，但是具体来说，比如有读者可能要问，如果我想计算加法，它应该怎么办呢？既然逻辑上只有两个值，那么自然地计算机就要使用二进制来表示数字了。二进制的加法非常简单，就以 $5+3$ 为例，我们可以这样计算：
\[
    \begin{array}{rr}
        &101 \\
        + & 011 \\
        \hline
        & 1000
    \end{array}
\]

逻辑门又是如何完成这一过程的呢？我们将它拆解成一个个小问题。当加到某一位时，我们需要考虑三个数：两个加数和来自后方的进位。例如下面这种情况
\[
    \begin{array}{rr}
        &\ldots_{\phantom{0}} 1_{\phantom{0}} \color{lightgray}\ldots\\
        + &\ldots_{\color{red}1} 0_{\color{blue}1} \color{lightgray}\ldots\\
        \hline
        & \cdots_{\phantom{0}} {\color{red}1}_{\phantom{0}} \color{lightgray}\ldots
    \end{array}
\]

如果考虑这一位相加得到的结果，后面相加得到结果的情况我们已经不关心了（因此标为浅灰色），在这里我们只关心从后方是否有进位（按照列竖式加法习惯，图中蓝色标注的下标 1）。再考虑两个加数的这一位分别为 1 和 0，所以 $1+0+1=2$，在结果栏写下一个 0（横线下方红色的 0），向前进位 1（写在前面一位下标的红色的 1），然后以同样的流程处理前一位。

记两个加数的这一位分别为 $x, y$，后方进位为 $c$，那么这一位的加和 $s$ 和向前进位 $c'$ 可以表示为
\[
    \begin{aligned}
        s &= (x \; \text{xor} \; y) \; \text{xor} \; c \\
        c' &= (x \land y) \lor (c \land (x \; \text{xor} \; y))
    \end{aligned}
\]

当然这并不是唯一正确的写法，实际上有很多正确的写法，证明就免了，如果读者有兴趣可以自行尝试，或许也可以找到另外的表达式。最简单粗暴的方法就是把两个加数的情况和是否带进位的情况全部列出来，分成 $2^3 = 8$ 种情况，就得到了如下的表，并逐一验证：
\[
    \begin{array}{cccccc}
        \hline
        \overset{\text{加数1}}{x} & \overset{\text{加数2}}{y} & \overset{\text{后方进位}}{c} & \overset{\text{加和}}{\text{sum}} & \overset{\text{向前进位}}{c'} & \overset{\text{结果位}}{s} \\
        \hline
        0 & 0 & 0 & 0 & 0 & 0\\
        0 & 0 & 1 & 1 & 0 & 1\\
        0 & 1 & 0 & 1 & 0 & 1\\
        0 & 1 & 1 & 2 & 1 & 0\\
        1 & 0 & 0 & 1 & 0 & 1\\
        1 & 0 & 1 & 2 & 1 & 0\\
        1 & 1 & 0 & 2 & 1 & 0\\
        1 & 1 & 1 & 3 & 1 & 1\\
        \hline
    \end{array}
\]

就像等式描述的一样，每一个输出的位都可以通过输入的逻辑运算用一定的电路连接表示，把多个电路串起来\footnote{串起来：对于加法这个例子，在网上\uhref{https://www.bing.com/search?q=\%E5\%85\%A8\%E5\%8A\%A0\%E5\%99\%A8}{搜索全加器}就可以很容易地搜到。}，就可以完成加法了。本质上我们的计算机 CPU 就是由这样的门电路与接线组成的\footnote{说明：实际上制造中，与非门、或非门使用更多，因为它们有更方便制造、体积较小、功耗低等优势。}。一个 CPU 需要大量门电路组合形成，现代的 CPU 包含数十亿个门电路，而一个门又由若干个微型的晶体管构成。为了让电路精确地实现我们预期的功能，需要精准地将电路雕刻在硅片上，这就是光刻技术如此重要的原因。但是山在那，总有人会去登的\footnote{山在那，总有人会去登：语出源自英国登山家 George Mallory 当被问及为何要攀登珠穆朗玛峰时的回答“因为山在那里”。‌刘慈欣的短篇小说\uhref{https://zhiqiang.org/resource/liucixin-mountain.html}{《山》}引用了这句话。写到大量的微晶体管以精妙地排布构成电路让我想起小说中从基本电路开始进化的的硅基生物，如果你看到这里看累了，去看看小说放松一下吧。}，两个多世纪的技术积累才造就了现代计算机的诞生，从逻辑门到通用计算机每一步的发展都凝聚着人类技术与智慧的结晶。

\newpage

\subsection{程序是怎么执行起来的}

擅长编程的读者或许对编程-编译-执行的路径再熟悉不过了，可少有人思考其中细节。理解程序是如何运行起来的其实是一个基础性的问题，但如果深究下去，这里的水很深：仅是从代码编写到程序运行的过程这一个问题，就足以写好几本书\footnote{好几本书：比如几本经典教材
    \begin{itemize}
        \item 程序如何编译出来：\uhref{https://repository.unikom.ac.id/48769/1/Compilers\%20-\%20Principles,\%20Techniques,\%20and\%20Tools\%20(2006).pdf}{《编译原理》}{(\emph{Compilers: Principles, Techniques, and Tools})}
        \item 计算机的结构：\uhref{https://www.cs.sfu.ca/~ashriram/Courses/CS295/assets/books/CSAPP_2016.pdf}{《深入理解计算机系统》}(\emph{Computer Systems: A Programmer's Perspective})
        \item 程序的结构：\uhref{https://web.mit.edu/6.001/6.037/sicp.pdf}{《计算机程序的构造和解释》}{(\emph{Structure and Interpretation of Computer Programs})}
    \end{itemize}
}了。因此我仅仅会从一个极简的视角来介绍 CPU 运行程序的流程，顺带解释必要的概念。让计算机执行程序前，我们首先需要思考“我们想让计算机做什么”并能把它讲明白。开发的第一步永远是明确需求，而后才是写代码让计算机执行，这一点贯彻到后续的机器学习也是一样的。

CPU 不是人类，它并不天然地理解我们的语言，不过或许并不应就这一点给我们带来的不便而感到沮丧：因为从人类手动完成一切计算到计算机的出现，电子器件的计算能力已经将人类从许多重复、繁琐的工作中解放出来。CPU 现在不能干的很多，但此刻更应该思考的是，它能干什么呢？这里我顺着\uhref{https://www.bilibili.com/video/BV1Lp4y167im}{这份CSAPP视频合集}的思路简单介绍一下。

现代的 CPU 通常包含复杂的\textoverset{Architecture}{架构}与\textoverset{Instruction Set}{指令集}，但是为了便于理解，我们先只考虑一个极度简化的 CPU，它就像是在一张“草稿纸”\footnote{草稿纸：比喻计算机的\textoverset{RAM}{内存}，暂且把它理解为每格写了一个整数，实际计算机中是字节。}上遵照着一份“指南”\footnote{指南：比喻计算机的程序，是计算机要执行的\textoverset{Instruction}{指令}。}运算。能干的事情也就是下面这几个指令（这里与主要的几种汇编语法都略有区别）：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
mov a, b  ; 将 b 的值赋给 a
add a, b  ; 将 a 和 b 相加，结果存入 a
sub a, b  ; 将 a 减去 b，结果存入 a
mul a, b  ; 将 a 乘以 b，结果存入 a
div a, b  ; 将 a 除以 b，保留整数部分，结果存入 a
jmp addr  ; 跳转到 addr 执行
je addr   ; 如果上一次运算结果为 0，则跳转到 addr 执行
jne addr  ; 如果上一次运算结果不为 0，则跳转到 addr 执行
jl addr   ; 如果上一次运算结果小于 0，则跳转到 addr 执行
cmp a, b  ; 比较 a 和 b 的值，设置标志位
\end{minted}

先解释一下这些指令名称的含义：
\begin{itemize}
    \item \texttt{mov}：\textbf{mov}e 的缩写，将一个数值从一个地方移动到另一个地方。
    \item \texttt{add}, \texttt{sub}, \texttt{mul}, \texttt{div}：\textbf{add}, \textbf{sub}tract, \textbf{mul}tiply, \textbf{div}ide 的缩写，加减乘除。
    \item \texttt{jmp}, \texttt{je}, \texttt{jne}, \texttt{jl}：\textbf{j}u\textbf{mp}, \textbf{j}ump if \textbf{e}qual, \textbf{j}ump if \textbf{n}ot \textbf{e}qual, \textbf{j}ump if \textbf{l}ess 的缩写，分别为跳转、当等于时跳转、当不等于时跳转、当小于时跳转。
    \item \texttt{cmp}：\textbf{cmp}are 的缩写，比较。
\end{itemize}

这里写作 \texttt{a, b} 的其实都表示内存上的一个地址，类似于如果给行编号，那么 \texttt{a, b} 就是行号。再引入一个额外的符号，\texttt{[a]} 表示取地址 a 上的值，例如当内存单元 \texttt{42} 中存着值 \texttt{64} 时，\texttt{[42]} 就表示 \texttt{64}，例如 \texttt{mov 10, [42]} 表示的就是把 \texttt{64} 号内存的值赋给 \texttt{10} 号内存。\texttt{\#x} 表示\textoverset{Immediate Value}{立即数值} x，例如 \texttt{\#10} 表示数值 \texttt{10} 本身，而非内存位置 \texttt{10}。那么我们可以写出一个简单的程序，例如把内存 \texttt{0} 位置\footnote{内存 \texttt{0}：按照计算机中的习惯，计数从 0 开始。}的值与内存 \texttt{1} 位置的加和存入内存 \texttt{2}：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
mov 2, 0    ; 将 0 号内存的值赋给 2 号内存
add 2, 1    ; 将 2 号内存和 1 号内存相加，结果存入 2 号内存
\end{minted}

又比如，如果我们想交换内存 \texttt{0} 和内存 \texttt{1} 位置的数值，可以这样写：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
mov 2, 0    ; 将 0 号内存的值赋给 2 号内存
mov 0, 1    ; 将 1 号内存的值赋给 0 号内存
mov 1, 2    ; 将 2 号内存的值赋给 1 号内存
\end{minted}

这个过程运行时\footnote{你先别管它怎么运行起来的。}看起来是这样的，右边的列表表示内存，每个元素是内存的一个单元，这里 $x_i$ 示意第 $i$ 个内存单元。$x,y$ 都是数，你可以把它带入 $1, 2$ 或者你想的任何数字，右侧的列表则表示对应的指令执行后的内存状态：
\[
    \begin{array}{l|l}
        \text{指令} & [x_1, x_2, x_3, \cdots] \\
        \hline
        \phantom{\triangleright} \; (\text{initial}) & [{\color{red!50}x}, {\color{blue!50}y}, \_, \ldots] \\
        \triangleright \; \text{mov 2, 0} & [{\color{red!50}x}, {\color{blue!50}y}, {\color{red!50}x}, \ldots] \\
        \triangleright \; \text{mov 0, 1} & [{\color{blue!50}y}, {\color{blue!50}y}, {\color{red!50}x}, \ldots] \\
        \triangleright \; \text{mov 1, 2} & [{\color{blue!50}y}, {\color{red!50}x}, {\color{red!50}x}, \ldots] \\
    \end{array}
\]

不过看到这里，不知读者是否发现了一个问题：内存中的 \texttt{2} 号位置在交换 \texttt{0} 号和 \texttt{1} 号位置的数值时被覆盖了。这种情况一般称为\textoverset{Side Effect}{副作用}\footnote{副作用：指令运行的过程中对其他地方产生的影响。}，但似乎不太可能既不修改其它内存，又交换数值\footnote{不太可能：在本例中确实有\uhref{https://www.cnblogs.com/cpoint/p/3367376.html}{奇技淫巧}可以在不设中间变量的情况下交换变量，只是它使用到了一些代数性质，既不方便，可读性和可拓展性也差。}。万一内存 \texttt{2} 储存了重要的数据，丢失了是很大的问题。那么怎么办呢？干脆设定某块区域可以随意用作临时存储\footnote{临时储存：可以理解为一种草稿纸，内容可以随时丢弃}，我们就此“发明”了\textoverset{Register}{寄存器}\footnote{寄存器：实际的 CPU 中，寄存器是 CPU 内部的一块存储区域，与内存的处理、读写速度等都有显著的不同。但是出于易于理解起见，我们这里仍把它当作一个特殊的内存区域。}。就假设我们接下来约定了地址 \texttt{0-7} 是寄存器，可以存储临时的数据。为了方便阅读，接下来把它们标记为 \texttt{r0} 到 \texttt{r7}。既然这样，\texttt{0-7} 的位置就可以用作临时存储了，但是同时它们也不适合作为输入输出\footnote{不适合：这里指的是不方便我们的讨论，实际程序中是靠一定的约定依靠寄存器传递参数的，但是这些规则可能会为清晰的说明带来困扰，所以在这里寄存器还是用作纯粹的草稿。}。所以这次我们把任务改为交换内存 \texttt{8} 和内存 \texttt{9}：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
mov r0, 8   ; 将 8 号内存的值赋给 0 号寄存器
mov 8, 9    ; 将 9 号内存的值赋给 8 号内存
mov 9, r0   ; 将 0 号寄存器的值赋给 9 号内存
\end{minted}

这样程序运行的过程中改变的就仅仅是我们视作数据内容\textoverset{Volatile}{易失}的寄存器，而内存中的数据则保持不变。这样我们再来写一个简单的求和程序，在内存 \texttt{8} 中存储了求和的起点地址，内存 \texttt{9} 中存储了求和的终点地址，为了方便起见，我们使用左闭右开区间，即包含起点，但不包含终点（一会就会看到它带来的方便）。最后将求和结果存入内存 \texttt{10}：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
mov r0, #0  ; 将 0 写入 0 号寄存器
mov r1, 8   ; 将 8 号内存的值赋给 1 号寄存器
mov r2, 9   ; 将 9 号内存的值赋给 2 号寄存器
loop:
    add r0, [r1]    ; 将 1 号寄存器指向的内存的值加到 0 号寄存器
    add r1, #1      ; 1 号储存器指向的内存地址加 1
    cmp r1, r2      ; 比较 1 号寄存器和 2 号寄存器的值
    jne loop        ; 如果不相等，跳转到 loop
mov 10, r0  ; 将 0 号寄存器的值存入 10 号内存
\end{minted}

严格来讲上面这段代码包含了前文还没引入标签的概念，其中的 \texttt{loop:} 就是一个标签，它是一个位置的别名\footnote{别名：例如在本例中，它指代 \texttt{add r0, [r1]} 所在的行}，也是填写在 \texttt{jmp}, \texttt{je}, \texttt{jne} 指令后的地址。

这个程序运行起来是怎么样的呢？假设我们在 \texttt{8} 号位置存储了起点地址 \texttt{15}，\texttt{9} 号位置存储了终点地址 \texttt{18}（它们虽然储存的是地址，从程序逻辑上指向的是内存块，但是本质上在 CPU 看来仍然是一种“整数”，只是这个整数记录了另一个整数的位置信息）。那么程序运行的过程大概是这样的（这里假设内存中 $x_{15}, x_{16}, x_{17}$ 分别存储了 \texttt{1, 2, 3}）：
\[
    \begin{array}{l|lll}
        \text{指令} & [r_0, r_1, r_2, \cdots, & x_8, x_9, x_{10}, \cdots, & x_{15}, x_{16}, x_{17}, \cdots]\\
        \hline
        \phantom{\triangleright} \; (\text{initial}) & [\_, \_, \_, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \\
        \triangleright \; \text{mov r0, \#0} & [0, \_, \_, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \quad \text{向 $r_0$ 写入 0}\\
        \triangleright \; \text{mov r1, 8} & [0, 15, \_, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \quad \text{将 $x_8$ 的 15 赋给 $r_1$}\\
        \triangleright \; \text{mov r2, 9} & [0, 15, 18, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \quad \text{将 $x_9$ 的 18 赋给 $r_2$}\\
        \triangleright \; \text{add r0, [r1]} & [1, 15, 18, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \quad \text{$r_1 = 15,$ 取 $x_{15}=1$ 加到 $r_0$}\\
        \triangleright \; \text{add r1, \#1} & [1, 16, 18, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \quad \text{$r_1$ 加 1 (指向 $x_{16}$)}\\
        \triangleright \; \text{cmp r1, r2} & [1, 16, 18, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \to (16 \neq 18, \text{跳回 loop}) \\
        \triangleright \; \text{add r0, [r1]} & [3, 16, 18, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \quad \text{$r_1 = 16,$ 取 $x_{16}=2$ 加到 $r_0$}\\
        \triangleright \; \text{add r1, \#1} & [3, 17, 18, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \quad \text{$r_1$ 加 1 (指向 $x_{17}$)}\\
        \triangleright \; \text{cmp r1, r2} & [3, 17, 18, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \to (17 \neq 18, \text{跳回 loop}) \\
        \triangleright \; \text{add r0, [r1]} & [6, 17, 18, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \quad \text{$r_1 = 17,$ 取 $x_{17}=3$ 加到 $r_0$}\\
        \triangleright \; \text{add r1, \#1} & [6, 18, 18, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \quad \text{$r_1$ 加 1 (指向 $x_{18}$)}\\
        \triangleright \; \text{cmp r1, r2} & [6, 18, 18, \cdots, & 15, 18, \_, \cdots, & 1, 2, 3, 4, \cdots] \to (18 = 18, \text{顺序执行}) \\
        \triangleright \; \text{mov 10, r0} & [6, 18, 18, \cdots, & 15, 18, 6, \cdots, & 1, 2, 3, 4, \cdots] \quad \text{将 $r_0$ 的 6 存入 $x_{10}$}
    \end{array}
\]

这个求和固然写的很好，但是我们又有一个问题，比方说下一次我们想写代码来求一块连续内存的均值，那么我们就需要再写一遍类似的代码，只是在最后加一个除法指令。这显然非常不经济实惠，因此需要把这个求和的过程给抽象出来，这就是\textoverset{Function}{函数}的概念。函数就是一段可以重复使用的代码块，它可以接受输入，产生输出。想的很好，但是我们要怎么实现呢？

我们先从日常生活经验来理解这么一件事情：你在做作业，突然感觉饿了，于是你拿起手机，打开了某外卖软件，点了一份外卖。这个过程中，你并不需要知道外卖是怎么做的，而在点完外卖后，你放下手机，继续做作业。我们从这个例子中可以得到什么启发呢？首先，原本的语境是做作业，点完外卖后应该要切换回做作业的场景，而不是紧接着打开某视频或者小说软件，这说明你需要记住你原本的工作做到哪里了。其次，你的行为是逐层嵌套的，要先拿起手机才能点外卖，但是点完之后要先退出外卖软件，然后才是放下手机。就像这样两个闭合的括号 $(())$，你需要先进入外层才能进入内层，反过来要先退出内层才能退出外层。我想这已经足以说明函数应当如何设计了：总的来说要有一个入口和一个出口，而且函数内部的操作应该是封闭的，用完要能够切换回原来的场景。

跳进函数很容易，只需要 \texttt{jmp} 到函数的入口执行代码就可以了，但是仔细一想，我们的函数调用完之后要怎么知道该回到哪里呢？这里我就要提到一个之前没有明说的地方，实际上执行程序时我写在每一行的指令都是有编号的，这个编号就是\textoverset{Program Counter}{程序计数器}\footnote{程序计数器：在实际的 CPU 中，程序计数器是一个寄存器，用来存储待执行的指令地址。}。与其它的寄存器不同，这个寄存器是有专门用途的，所以称为\textoverset{Special-Purpose Register}{专用目的寄存器}，而其它可以随意用作存储的寄存器称为\textoverset{General-Purpose Register}{通用目的寄存器}。在前文中指令左侧画的小三角就是程序计数器的表示，所以“记住”运行到了哪里实际上只需要把程序计数器的值存起来，然后在函数结束后再把它取出来就可以了。

最简单的想法是，再设置一个寄存器专门用来存储要返回的地址，不过这个想法存在一个问题：如果在函数里面再次想要调用其它函数，那么这个寄存器就会被覆盖，也就是说内层函数调用成功并返回了，外层函数却不知道该回到哪了。为此我们发现存储应该是分层的，每进入一个函数就应该有一个新的存储空间，当退出时再把这个存储空间销毁，而且进入和退出的顺序是相反的（这种顺序通常称为\textoverset{Last In First Out}{后进先出}），这就引出了\textoverset{Stack}{栈}。

这里画一幅图来说明栈的概念：想象一张有很多个格子的纸条，我们有一支带橡皮的铅笔（下面画一个小的箭头表示这支“笔”），刚开始栈是空的，里面什么也没有存储。一条边界固定，称作栈底，另一条边界线会变化，称作栈顶，两线重合表明栈是空的。
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[>=Stealth]
        \fill [gray, opacity=0.15] (-1, 0) rectangle (10, 1);
        \draw (-1, 0) -- (10, 0);
        \draw (-1, 1) -- (10, 1);
        \foreach \x in {0, 1, ..., 9} {
            \draw (\x, 0) -- (\x, 1);
        }
        \draw [thick, red] (0, 0) node [below] {栈底(栈顶)} -- (0, 1);
        \draw [->] (0.5, 1.75) node [above] {读写头} -- (0.5, 1.25);
        \node at (4.5, -0.8) {空栈};
    \end{tikzpicture}
\end{figure}

当我们向其中加入一个元素时，就把这个元素放在栈顶，同时读写头指向下一个位置。这个过程称为\textoverset{Push}{压栈}，例如上面的空栈加入一个元素后的状态是这样的：
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[>=Stealth]
        \fill [gray, opacity=0.15] (-1, 0) rectangle (10, 1);
        \fill [green, opacity=0.5] (0, 0) rectangle (1, 1);
        \draw (-1, 0) -- (10, 0);
        \draw (-1, 1) -- (10, 1);
        \foreach \x in {0, 1, ..., 9} {
            \draw (\x, 0) -- (\x, 1);
        }
        \draw [thick, red] (0, 0) node [below] {栈底} -- (0, 1);
        \draw [thick, red] (1, 0) node [below] {栈顶} -- (1, 1);
        \draw [->] (1.5, 1.75) node [above] {读写头} -- (1.5, 1.25);
        \node at (0.5, 0.5) {$1$};
        \node at (4.5, -0.8) {栈 (大小为 1)};
    \end{tikzpicture}
\end{figure}

再加入一个元素呢？这个元素又会被跟着放在栈顶，读写头的位置加 1, 即指向下一个位置，就像这样：
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[>=Stealth]
        \fill [gray, opacity=0.15] (-1, 0) rectangle (10, 1);
        \fill [green, opacity=0.5] (0, 0) rectangle (2, 1);
        \draw (-1, 0) -- (10, 0);
        \draw (-1, 1) -- (10, 1);
        \foreach \x in {0, 1, ..., 9} {
            \draw (\x, 0) -- (\x, 1);
        }
        \draw [thick, red] (0, 0) node [below] {栈底} -- (0, 1);
        \draw [thick, red] (2, 0) node [below] {栈顶} -- (2, 1);
        \draw [->] (2.5, 1.75) node [above] {读写头} -- (2.5, 1.25);
        \node at (0.5, 0.5) {$1$};
        \node at (1.5, 0.5) {$2$};
        \node at (4.5, -0.8) {栈 (大小为 2)};
    \end{tikzpicture}
\end{figure}

当我们要取出一个元素时，就把栈顶的元素取出，同时读写头向前移动一个单元。这个过程称为\textoverset{Pop}{弹栈}，例如上面的栈弹出一个元素后的状态是这样的：
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[>=Stealth]
        \fill [gray, opacity=0.15] (-1, 0) rectangle (10, 1);
        \fill [green, opacity=0.5] (0, 0) rectangle (1, 1);
        \draw (-1, 0) -- (10, 0);
        \draw (-1, 1) -- (10, 1);
        \foreach \x in {0, 1, ..., 9} {
            \draw (\x, 0) -- (\x, 1);
        }
        \draw [thick, red] (0, 0) node [below] {栈底} -- (0, 1);
        \draw [thick, red] (1, 0) node [below] {栈顶} -- (1, 1);
        \draw [->] (1.5, 1.75) node [above] {读写头} -- (1.5, 1.25);
        \node at (0.5, 0.5) {$1$};
        \draw [->] (1.5, -0.25) -- (1.5, -0.75) node [below] {弹出 $2$};
        \node at (4.5, -0.8) {栈 (大小为 1)};
    \end{tikzpicture}
\end{figure}

栈就像一摞盘子，每次放盘子都是放在最上面，取盘子也是从最上面取（我们不讨论一次拿走多个盘子的情况）。只需要知道如何往上放和如何取下来就可以操作了。不过盘子能叠的高度是有限的，正如内存是有限的，但是假使我们的程序没有太深层的函数调用，这里就假设是 80 层\footnote{80：这个数字有其历史原因，早期计算机终端通常只有 80 列，因此 80 个字符以内成为了 Linux 编码的规范，这个规范延续到了很多语言的编程风格建议之中，成为一种约定俗成。这里限制深度 80 意味着如果使用“标准”的列宽，一行能写下所有的左括号。}，那么我们只需要分配 80 个单位的连续内存空间。对于人类来讲，匹配十几层的括号已经不可思议，80 层更是相当深了\footnote{相当深：相对大部分应用程序确实是这样的，但是对于一些特殊的部分，例如搜索、嵌套\textoverset{Callback}{回调}、\textoverset{Ray Tracing}{光路追踪}等，完全可能达到成百上千层。}。除此之外我们需要一个寄存器来存储栈顶的位置，其称为\textoverset{Stack Pointer}{栈指针}。于是我们大手一挥，把 \texttt{8} 号位置作为\textoverset{Stack Pointer}{栈顶指针}，用一个别名 \texttt{sp} 代表它。又把 \texttt{20} 到 \texttt{99} 号内存分配给栈。如果暂且不考虑调用层数太深的问题。加下来函数调用要怎么样呢？

首当其冲的是把当前的下一条指令地址压到栈顶，接下来是把栈顶指针加 1，然后再 \texttt{jmp} 到函数的入口\footnote{\texttt{jmp}：本质上读者可能已经发现了，\texttt{jmp} 实际上就是把某个值写入程序寄存器，这样一来 CPU 就会跳转到这个地址执行了。}。在函数结束时，我们需要先恢复栈顶指针，再把栈顶我们事先存的下一条地址弹出来，最后再 \texttt{jmp} 到这个地址。

看起来大概像这样，初始时栈中可能已经有了一些内容，我们把下一条指令的地址写入栈，栈顶右移。
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[>=Stealth]
        \fill [gray, opacity=0.15] (-1, 0) rectangle (10, 1);
        \fill [green, opacity=0.5] (0, 0) rectangle (3, 1);
        \draw (-1, 0) -- (10, 0);
        \draw (-1, 1) -- (10, 1);
        \foreach \x in {0, 1, ..., 9} {
            \draw (\x, 0) -- (\x, 1);
        }
        \draw [thick, red] (0, 0) node [below] {栈底} -- (0, 1);
        \draw [thick, red] (3, 0) node [below] {栈顶} -- (3, 1);
        \draw [->] (3.5, 1.75) node [above] {读写头} -- (3.5, 1.25);
        \node at (0.5, 0.5) {...};
        \node at (1.5, 0.5) {...};
        \node at (2.5, 0.7) {next};
        \node at (2.5, 0.3) {inst.};
        \node at (4.5, -1) {栈 (大小为 3)};
    \end{tikzpicture}
\end{figure}

等函数执行完要返回到原先的位置时，我们先把栈顶指针左移，再把栈顶的下一条指令地址取出来，最后 \texttt{jmp} 到这个地址。
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[>=Stealth]
        \fill [gray, opacity=0.15] (-1, 0) rectangle (10, 1);
        \fill [green, opacity=0.5] (0, 0) rectangle (2, 1);
        \draw (-1, 0) -- (10, 0);
        \draw (-1, 1) -- (10, 1);
        \foreach \x in {0, 1, ..., 9} {
            \draw (\x, 0) -- (\x, 1);
        }
        \draw [thick, red] (0, 0) node [below] {栈底} -- (0, 1);
        \draw [thick, red] (2, 0) node [below] {栈顶} -- (2, 1);
        \draw [->] (2.5, 1.75) node [above] {读写头} -- (2.5, 1.25);
        \node at (0.5, 0.5) {...};
        \node at (1.5, 0.5) {...};
        \draw [->] (2.5, -0.25) -- (2.5, -0.75) node [below] {弹出指令};
        \node at (4.5, -0.6) {栈 (大小为 2)};
    \end{tikzpicture}
\end{figure}

另外，在前面的例子中，起始、终止地址、写入位置等参数是通过手动指定的 \texttt{8, 9, 10} 位置来传递的，但是我们显然不想为每一个函数都手动指定参数要放在哪里，这很麻烦，需要一个清晰、明确的规则来传递参数\footnote{规则：x86, x86-64 Linux, x86-64 Windows, ARM 各有各的传法。}。此处设定一个比较简单的规则：用 9 号位置专门储存函数得到的结果，起别名 \texttt{ans}。同时做这样一个限制：函数最多有 4 个参数\footnote{4 个参数：这个限制是为了简化问题，实际计算机参数传递中对于多出的部分会用到栈，但是这里不允许使用栈传递，4 这个数字是按照 x86-64 Windows 可用的寄存器参数传递来的。}，把 \texttt{10-13} 位置用作参数存储，给它们分别起名 \texttt{arg0} 到 \texttt{arg3}。那么在我们做出了看起来还算满意的内存分配后，目前看来大概是这么分布的\footnote{说明：实际的计算机中栈通常是从后向前增长的，与此处不同，注意区分。}：
\begin{figure}[H]
    \centering
    \begin{tikzpicture}[>=Stealth]
        \fill [gray, opacity=0.15] (0, 0) rectangle (13, 0.2);
        \fill [red, opacity=0.5] (0, 0) rectangle (0.8, 0.2);
        \node [below, red, opacity=0.5] at (0, 0) {\texttt{r0-r7}};
        \fill [orange, opacity=0.7] (0.8, 0) rectangle (0.9, 0.2);
        \node [above left, orange, opacity=0.7] at (1.0, 0.2) {\texttt{sp}};
        \fill [yellow] (0.9, 0) rectangle (1.0, 0.2);
        \node [below, yellow] at (1.0, 0) {$\phantom{0}$\texttt{ans}$\phantom{0}$};
        \fill [green] (1.0, 0) rectangle (1.4, 0.2);
        \node [above right, green] at (0.9, 0.2) {\texttt{arg0-arg3}};
        \fill [cyan, opacity=0.8] (2, 0) rectangle (10, 0.2);
        \node [below, cyan, opacity=0.8] at (6, 0) {栈};
        \draw (0, 0) -- (13, 0);
        \draw (0, 0) -- (0, 0.2);
        \draw (0, 0.2) -- (13, 0.2);
        \draw [cyan!80!black, ->] (2, -0.5) node [below] {栈底} -- (2, -0.1);
        \node [below right, gray] at (10, 0) {可自由使用内存};
    \end{tikzpicture}
    \caption{设想中的一种内存分配方式}
\end{figure}

这样我们就可以以“函数调用”的方式求 \texttt{101-103} 号位置均值并存储到 \texttt{100} 位置了，不过我们需要在每次调用函数前后都要写一段代码来维护栈，如果我们手写一切代码来维护大概是这样的：

先是 \texttt{sum} 函数：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
sum:
    mov r0, #0  ; 将 0 写入 0 号寄存器
    mov r1, arg0    ; 将 arg0 的值赋给 1 号寄存器
    mov r2, arg1    ; 将 arg1 的值赋给 2 号寄存器

loop:
    add r0, [r1]    ; 将 1 号寄存器指向的内存的值加到 0 号寄存器
    add r1, #1      ; 1 号储存器指向的内存地址加 1
    cmp r1, r2      ; 比较 1 号寄存器和 2 号寄存器的值
    jne loop        ; 如果不相等，跳转到 loop
    mov ans, r0     ; 将 0 号寄存器的值存入 ans
    sub sp, #1      ; 栈顶指针减 1
    jmp [sp]        ; 跳转到栈顶指向的指令地址
\end{minted}

再是 \texttt{mean} 函数：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
mean:
    mov [sp], label1; 将 label1 的地址存入栈顶
    add sp, #1      ; 栈顶指针加 1
    jmp sum         ; 跳转到 sum 函数，无需改变参数

label1:
    sub arg2, arg1  ; 将 arg2 减去 arg1 得到求和的长度
    div ans, arg2   ; 将 ans 除以 arg2 得到均值
    sub sp, #1      ; 栈顶指针减 1
    jmp [sp]        ; 跳转到栈顶指向的指令地址
\end{minted}

最后是主程序：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
main:
    mov 101, #1     ; 将 1 存入 101 号内存
    mov 102, #2     ; 将 2 存入 102 号内存
    mov 103, #3     ; 将 3 存入 103 号内存
    mov arg0, #101  ; 将起始地址 101 存入 arg0（含）
    mov arg1, #104  ; 将终止地址 104 存入 arg1（不含）

    mov [sp], label2; 将 label2 的地址存入栈顶
    add sp, #1      ; 栈顶指针加 1
    jmp mean        ; 跳转到 mean 函数
label2:
    mov 100, ans    ; 将 ans 的值存入 100 号内存
\end{minted}

最终我们总体的程序结构是这样的：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
jmp main
sum:  ...
mean: ...
main: ...
\end{minted}

读者可以一步步地思考，假设 \texttt{sp} 最开始存储了空的栈顶 \texttt{20}，并体会它是如何通过精确的操作完成函数调用的。不过随之而来的我们发现每次调用函数前起手都要写这样一段
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
    ...             ; 前面的代码
    mov [sp], label1; 将 label1 的地址存入栈顶
    add sp, #1      ; 栈顶指针加 1
    jmp func        ; 跳转到 func 函数
label:              ; 为了后续继续执行添加标签
    ...             ; 原本的后续代码
\end{minted}

同样在函数结束时又要写一段
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
    ...             ; 函数内部
    sub sp, #1      ; 栈顶指针减 1
    jmp [sp]        ; 跳转到栈顶指向的指令地址，函数结束
\end{minted}

实在是太麻烦了，显然属于重复性的劳动，于是我们从中提炼出\textoverset{Call}{调用}和\textoverset{Return}{返回}的指令。既然这样，就给了简化写法的空间：定义一个指令 \texttt{call func}，它自动完成函数开始时压栈、栈顶移动和跳转到函数的操作。再定义 \texttt{ret}，它自动完成栈顶回退、跳转到栈顶指向的地址的操作。把这个过程抽象出来之后，我们的程序就变成了这样：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{asm}
jmp main
sum:
    mov r0, #0  ; 将 0 写入 0 号寄存器
    mov r1, arg0    ; 将 arg0 的值赋给 1 号寄存器
    mov r2, arg1    ; 将 arg1 的值赋给 2 号寄存器
loop:
    add r0, [r1]    ; 将 1 号寄存器指向的内存的值加到 0 号寄存器
    add r1, #1      ; 1 号储存器指向的内存地址加 1
    cmp r1, r2      ; 比较 1 号寄存器和 2 号寄存器的值
    jne loop        ; 如果不相等，跳转到 loop
    mov ans, r0     ; 将 0 号寄存器的值存入 ans
    ret
mean:
    call sum        ; 直接把 arg0 和 arg1 传给 sum
    sub arg2, arg1  ; 将 arg2 减去 arg1 得到求和的长度
    div ans, arg2   ; 将 sum 得到的 ans 除以 arg2 得到均值
    ret
main:
    mov 101, #1     ; 将 1 存入 101 号内存
    mov 102, #2     ; 将 2 存入 102 号内存
    mov 103, #3     ; 将 3 存入 103 号内存
    mov arg0, #101  ; 将起始地址 101 存入 arg0（含）
    mov arg1, #104  ; 将终止地址 104 存入 arg1（不含）
    call mean       ; 直接把 arg0, arg1, arg2 传给 mean
    mov 100, ans    ; 将 mean 得到的 ans 存入 100 号内存
\end{minted}

但是其实抽象远没有结束，还可以进一步提炼出更精简的代码。我们感觉直接操作指令的方式过于野蛮了，但是我们可以写一个简单的文本替换程序来帮我们从较为简洁的代码生成这些指令。我们假设有这样一个程序，能完成如下的替换：

\begin{center}
\begin{tabular}{c|c|c}
    \hline 
    \textbf{原文本} & \textbf{替换后} & \textbf{说明} \\
    \hline
    ``...'' & ; ... & 注释 \\[5pt]
    ; & (换行) & 换行 \\[5pt]
    \texttt{123} & \texttt{\#123} & 立即数 \\[5pt]
    \texttt{x123} & \texttt{123} & 内存地址 \\[5pt]
    \texttt{a += b} & \texttt{add a, b} & 加法 \\[5pt]
    \texttt{a -= b} & \texttt{sub a, b} & 减法 \\[5pt]
    \texttt{a *= b} & \texttt{mul a, b} & 乘法 \\[5pt]
    \texttt{a /= b} & \texttt{div a, b} & 除法 \\[5pt]
    \texttt{a = b} & \texttt{mov a, b} & 赋值 \\[5pt]
    \texttt{return a} & $\boxed{\begin{array}{l} \texttt{mov ans, a} \\ \texttt{ret} \end{array}}$ & 返回 \\[20pt] 
    \texttt{if a != b jmp addr} & $\boxed{\begin{array}{l} \texttt{cmp a, b} \\ \texttt{jne addr} \end{array}}$ & 不等跳转 \\[20pt]
    \texttt{if a == b jmp addr} & $\boxed{\begin{array}{l} \texttt{cmp a, b} \\ \texttt{je addr} \end{array}}$ & 等于跳转 \\[20pt]
    \texttt{if a < b jmp addr} & $\boxed{\begin{array}{l} \texttt{cmp a, b} \\ \texttt{jl addr} \end{array}}$ & 小于跳转 \\[20pt]
    \texttt{do} \{...\} \texttt{while (a != b)} & $\boxed{\begin{array}{l} \texttt{loop\_i:} \\ \quad\texttt{...} \\ \texttt{cmp a, b} \\ \texttt{jne loop\_i} \end{array}}$ & 循环，其中 i 为自动分配的编号 \\[40pt]
    \hline
\end{tabular}
\end{center}

这样事情会变得简单很多，我们只需要写出一个更加易于理解的代码，再让这个文本替换工具把它翻译成可以被执行的指令就可以了。例如对于前面的例子，我们可以写出这样的代码（为了美观起见给每一行加上分号结尾）：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{c}
jmp main

sum:
    r0 = 0; r1 = arg0; r2 = arg1;
    do {
        r0 += [r1];
        r1 += 1;
    } 
    while (r1 != r2);
    return r0;

mean:
    call sum;
    arg2 -= arg1;
    ans /= arg2;
    ret;

main:
    x101 = 1; x102 = 2; x103 = 3; arg0 = 101; arg1 = 104;
    call mean;
    x100 = ans;
\end{minted}

事实上这个“文本替换程序”就已经是\textoverset{Compiler}{编译器}的雏形了，而这里抽象出来的更适合人类阅读的代码再往下走进行逐层的抽象就会一步步地走向高级语言。熟悉 C 语言的读者应该已经发现此处我是参考了 C 语言的语法来设计的，实际上 C 语言的设计就是为了更好地表达汇编语言而诞生，最初始的 C 语言差不多每句代码都对应一句汇编，很多现代 C 语言的特性是后续才慢慢添加的。这里我们就不再深入这个话题了，感兴趣的读者可以自行了解编译器的工作原理。

既然我们看完了极简的 CPU 模型，我想还是稍微提几句现代的 CPU 为好。往下（硬件）看，现代的 CPU 指令显然比这个模型丰富的多，而且通常是多核的，每个核都有自己的寄存器、程序计数器、栈指针等。寄存器也不只是看起来的几个，而是加了另一层的抽象，使用寄存器重命名技术将物理寄存器映射到逻辑寄存器。为了提升速度，在 CPU 和内存中间又插入了多级的\textoverset{Cache}{缓存}，这样 CPU 不用每次都去内存中读取数据，而是先读取缓存，如果缓存中没有再去内存中读取。在执行时，CPU 以其优化技术会对指令进行\textoverset{Out-of-Order Execution}{乱序执行}，而并不一定严格地按照代码的顺序。流水线执行、\textoverset{SIMD}{单指令多数据}、\textoverset{Branch Prediction}{分支预测}等技术也都是现代 CPU 的特色，它们将大大提升 CPU 的性能。

往上（软件）看，从 C 语言或者其它基础语言为基石构建的高级语言拥有了越来越丰富的特色，基于它们开发的各种库与框架也让程序员写出更加可靠、高效而又可复用的代码，可以更加专注于业务逻辑的开发，这些环环相扣构成了一张严密的逻辑网络。不同的\textoverset{Programming Paradigm}{编程范式}、\textoverset{Design Pattern}{设计模式}、\textoverset{Software Architecture}{软件架构}等概念也让程序员们在开发时有了更多的选择，而这些都是在计算机科学的基础上发展起来的。

在这里我再稍微点一下这一章的题目。本章的题目毕竟是逻辑亦数据，但是这里逻辑和数据似乎是分离开的：代码是代码，数字是数字，它们的关系又体现在哪里呢？其实这里为了理解，呈现的已经是一个经过抽象的版本，在 CPU 看来，每一条指令其实也是若干个字节。在内存中，指令和数据是混杂在一起的，只不过 CPU 会根据指令的不同来对待它们。在更高层次上，数据也可以是代码，代码也可以是数据。

但是接下来转头看向 GPU，我们将会看到一个全然不同的世界。

\newpage

\subsection{那么，GPU 呢？}

GPU，全称\textoverset{Graphics Processing Unit}{图形处理器}，是一种专门用来处理图形计算的处理器。打游戏的同学或许知道，为了打开高画质高刷新的游戏，需要一块强大的显卡，显卡的核心就是 GPU。都是执行指令，CPU 和 GPU 有什么区别呢？

在回答这个问题前我想有必要提出一个更为根本性的问题：渲染图形提出了怎样的特别的需求？让我们举一个最简单的例子：在平面上绘制一个圆。我们且不讨论怎么把圆加载到屏幕上，且就假设我们只需要把每个点都计算出来，或者更为具体地：在一个高 1080 宽 1920 的数组中计算出每个像素的颜色\footnote{方便起见，这里只考虑黑白颜色。}，按照惯例，黑色是 0，白色是 255。看起来很简单，我在这里用一份 C 语言代码来实现这个功能：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{c}
unsigned char img[1080][1920];

void draw_circle(int x, int y, int r) {
    for (int i = 0; i < 1080; i++) {
        for (int j = 0; j < 1920; j++) {
            if ((i - x) * (i - x) + (j - y) * (j - y) < r * r) {
                img[i][j] = 255;
            }
        }
    }
}
\end{minted}

原理本身是十分简单的，但是这段代码读下去我们无不发现一件事情：两个循环的次数一乘，单单渲染一个圆就需要 $1080 \times 1920 = 2073600$ 次的计算，考虑到加法、乘法、写入、读取都要时间，这个数字是相当大的。如果要处理的几何体多了，那么一个程序不说跑上 120 FPS \footnote{FPS：\textoverset{Frame Per Second}{帧每秒}的缩写，也称作帧率，许多游戏都有帧率设置。}的高速刷新了，或许连 30 FPS 都难保证。但是计算的需求本身客观存在，我们无法改变这个事实，那么该怎么办呢？

按照老规矩，我们应该先想想，对于人类来说，“想象一个圆”这个过程是如何发生的。我们显然不是在脑海中一个一个像素地去计算，而是直接画出一条边界，然后成片地填充。与逐像素刷新过去相比，这是“一瞬间”的事情，每个像素同时计算了出来。这就叫做\textoverset{Parallel Computing}{并行计算}，喷颜料总比一笔笔涂快，为了高效进行并行计算，GPU 诞生了。

有一个虽然不太严谨但是很形象的\uhref{https://www.zhihu.com/question/22219245/answer/365354011}{比喻}：CPU 就像是大学生，有几个核就有几个大学生，他们都很聪明，但是只能做一件事情。GPU 如果有几千个核，就像是几千个小学生，虽然每个人都不太聪明，只能完成简单的任务，但是适合完成大规模的任务。这个比喻虽然不够准确，也有人对这样的比喻提出过\uhref{https://zhuanlan.zhihu.com/p/60627768}{质疑}，但是可以让我们对 CPU 和 GPU 有一个直观的认识。一个更为细致的\uhref{https://www.bilibili.com/video/BV1wbcdeWENh}{解释}是 CPU 可以完成细致的分支预测等工作，大大提高了处理了复杂逻辑的能力，然而 GPU 并不适合处理\textoverset{Branch Diverge}{分支分歧}，分支语句会让 GPU 的并行计算效率大大降低（见 Nvidia 的\uhref{https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/sourcelevel/divergentbranch.htm}{文档}）。

总的来讲，CPU 有少量的寄存器和算数逻辑单元，适合处理复杂的逻辑运算。但是 GPU 有一个许多的线程，每个线程都有自己的多个寄存器。同时有多个运算单元\footnote{运算单元：在 Nvidia 的显卡中通常称为 CUDA (Compute Unified Device Architecture) 核心}来提供大规模的并行计算。这里不多介绍 GPU 的具体架构与底层组成，因为 GPU 的架构是多变的，不同的厂商、不同的型号都有不同的架构，而且 GPU 的架构也在不断地发展。

GPU 上要运行的指令所属的指令集与 CPU 上并不相同，甚至不同型号的 GPU 也有不同的指令集，因此自然地，程序需要适配到自己的 GPU 上。经常玩游戏的同学可能会发现不少游戏在启动时会有一个正在编译\textoverset{Shader}{着色器}的过程，或许不少人也好奇过\uhref{https://www.bilibili.com/video/BV1zi421h7tJ}{为什么}。实际上这个过程就是把图形渲染的代码编译成 GPU 可以执行的指令，就像不同的语言需要用不同的编译器一样，GPU 驱动中通常会包含一个着色器编译器，用来把着色器翻译成适配具体 GPU，可以被顺利执行的指令。

从实用的角度说，如果只是作为游戏玩家，我们只需要考虑什么显卡算力够用，花钱买卡就可以，但是游戏厂要考虑的就多了。游戏开发者为了渲染出更加逼真的画面需要了解 GPU 的\textoverset{Rendering Pipeline}{渲染流水线}，\uhref{https://www.bilibili.com/video/BV1MJ411u7Bc}{如何借助图形化库与 GPU 交互}，以及如何使用着色器来实现特效、如何计算光线追踪。

但是话又说回来，这渲染图形、纹理填充和机器学习又有什么关系呢？本质上是因为机器学习需要大量的矩阵运算，需要大量加法、乘法操作，因此这种重复性的操作也可以交给 GPU 并行处理。随着人工智能的快速发展，GPU 开始加入了专门加速矩阵运算的单元。例如 Nvidia 在 2017 年就向其生产的 GPU 中加入了\textoverset{Tensor Core}{\uhref{https://www.nvidia.com/en-us/data-center/volta-gpu-architecture/}{张量运算核}}\footnote{张量：深度学习中指的是一个高维的数组。}。

作为机器学习的使用者，我们显然也需要了解如何使用 GPU，不过更重要的是如何用好矩阵或张量运算的能力，所以侧重点有些不同。首先，无论出于什么用途，为了让主板识别到 GPU 与之正常交互需要安装 GPU 驱动。当购买预装了 Nvidia 显卡的电脑而言，一般厂家已经事先在 Windows 系统上安装了驱动，免去了手动安装的麻烦。然而当我们自己装机或者安装其它系统时，我们就不得不自己走这个流程。科研和工业环境中常常考虑到开源、高性能等优点常常选择 Ubuntu 系统，然而\uhref{https://linuxconfig.org/how-to-install-the-nvidia-drivers-on-ubuntu-22-04}{在 Ubuntu 上安装 Nvidia 驱动}的各种问题常常被人诟病，配环境本身就相当令人头疼（其实是因为 Linux 内核经常改动，而到现在仍然很难做内核态程序的兼容性适配）。说句题外话，许多库因为快速的更新迭代，库的依赖关系常常错综复杂，显卡驱动只是其中的一例。因此试图在自己的设备上复现论文中的科研成果时，我们常常感到配好环境几乎是成功的一半。这就是灵活性的另一面，与 Windows 上开箱即用的软件体验是全然不同的。

再说说 Nvidia 显卡的 CUDA Toolkit，类似着色器编译器等内容虽然已经在驱动中了，但是它只是一些特殊的预定义的运算。如果要更精细地调控运算，并从源代码开始编译 CUDA 的程序，特别是用 C/C++ 开发，就需要下载 CUDA Toolkit，因此在配置需要 GPU 加速的项目中，读者常常会发现需要安装 CUDA Toolkit，其最重要的作用就是提供适用于 GPU 的编译器。适当了解\uhref{https://blog.csdn.net/qq_42406643/article/details/109545766}{几个工具之间的关系}对理解配置环境时干了什么是有益的。

这时相信有人会问，平时运行程序时也不需要自己编译，那有没有这样一个程序或者工具可以让我们开箱即用地使用 GPU 完成矩阵运算呢？答案是，有的，Torch 和 TensorFlow 就包装掉了底层的细节，可以方便地完成这些运算，而在科研环境中，Torch 的 Python 接口 PyTorch 的使用尤其普遍。这时自然有一个问题：GPU 的版本不同，预编译的程序怎么适配不同GPU 版本呢？如果我们打开\uhref{https://pytorch.org/}{PyTorch 的官方网页}，便会发现，其中有一个选项是 Compute Platform。CUDA 是向后兼容的，也就是说新版本的硬件可以运行旧版本的代码，这意味着我们需要根据自己的硬件支持的 CUDA 版本做出\uhref{https://blog.csdn.net/binbinczsohu/article/details/143505636}{选择}。通常推荐选择 PyTorch 官网上提供的小于等于电脑 CUDA 版本的最新版本。例如，如果在命令行运行 \texttt{nvidia-smi} 得到的 CUDA 版本为 12.5，然而 PyTorch 官网页面提供 11.8, 12.4, 12.6 这三个版本，那么在两个满足条件的版本中选择一个更大的，12.4 版本就是推荐安装的版本，把下方的命令，例如：
\begin{minted}[bgcolor=gray!15, frame=single, framesep=10pt, baselinestretch=1.2]{bash}
pip3 install torch torchvision torchaudio --index-url \
https://download.pytorch.org/whl/cu124
\end{minted}
复制到命令行运行即可成功安装。当然如果你的 CUDA 版本刚好在页面上就不需要思考，可以直接安装了。事实上当我们在运行 Torch 并将矩阵调度到 GPU 计算时，它帮我们完成了矩阵数据的传输、把运算任务划分为多个\textoverset{Thread Block}{线程块}再交给 GPU 的工作。在 GPU 中的\textoverset{Streaming Multiprocessor}{流式多处理器}将线程块以\textoverset{Warp}{线程束}为单位调度，交给若干个 CUDA 核心与张量运算核共同完成矩阵的计算，再将内容写回显存的工作。而这些都被抽象成了一条条的矩阵运算代码，隐去了底层实现的细节，把它们交给了库。这让我们可以从繁琐的逻辑抽离，可以专心于数据的运算。

\subsection{位运算与bit-flag}